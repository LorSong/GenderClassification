# GenderClassification

Репозиторий для размещения тестового задания от NtechLab.  
Основная работа - создание модели, которая определяет пол человека по изображению его лица.
Основной фреймворк - TensorFlow 2

## Описание файлов
<details>
  <summary>Раскрыть</summary><br/>
  
  1. MaxSubArray.py - содержит функцию findMaxSubArray(A) к первому заданию.
  2. GenderClassification_#.ipynb - Jupyter notebooks с шагами по обучению сети
  3. process.py - cкрипт для использования нейросети (смотри инструкцию ниже)
  4. model - папка с tf.model, которую использует скрипт process.py для загрузки модели
  5. train.py - скрипт для обучения нейросети. Создает папку model. (смотри инструкцию ниже). 
  6. Gender_clf_utils.py - дополнительные функции, которые были созданы во экспериментов с моделями. Используются в Jupyter notebooks
</details>

## Описание хода работы
<details>
  <summary>Раскрыть</summary><br/>  
  Создание классификатора изображений является одной из стандартных задачач машинного обучения.
  Для этих целей лучше всего подходят сверточные нейронные сети (CNN), способные обнаруживать детали на изображениях
  вне зависимости от их расположения.<br/>
  Для создания моделей я использовал TensorFlow 2, так как имел опыт работы с этим фреймворком
  
  Моей целью была попытка достичь точности в 99%.<br/>
  Результат: 98% точности на валидационном сете. <br/>
  Также были обнаружены аномалии в данных, которые препятствуют достижению более высоких результатов. 
  Конечно подобные аномалии могут встречаться и в реальном мире. Но в этом случае определение пола по лицу, 
  не представляется возможным.
  <br/>
  
  Я проводил эксперименты и записывал свои действия в Jupyter notebook. Для вычислений использовалась локальная видеокарта Nvidia 1050ti.
  
  Описание основных шагов:
  
  * Создал план работы. Прочитал статьи по обработке изображений, CNN, классификации.
  * Подготовил и просмотрел данные. 
  Так как количество изображений велико, я решил не применять дополнительной обработки.
  Изначально планировалась работа в GoogleColab, но загрузка данных часто давал ошибки. Для упрощения чтения разместил файлы в подпапки. 
  Но скорость загрузки изображений периодически сильно падала.
  * Формирование датасета с помощью tf.data. Изображения были приведены к единому размеру. Масштаб решил не сохранять, так как 
  после изменения размера, значительных искажений я не заметил. <br/>
  Возможно, стоило проверить размеры всех изображений для выявления аномалий, но так как их загрузка занимает довольно 
  много времени, решил пропустить этот шаг. <br/>
  Размер изображений выбран 96х96 для совместимости с обученными моделями tf.hub
  
  * Для получения базовой метрики я применил простую последовательную CNN модель с 4 сверточными и 3 полностью соединенными слоями.
  Во всех моделях испольузется последний слой с одним нейроном и sigmoid активацией для получения вероятностей принадлежности к классу.
  Loss функция - BinaryCrossentropy. Метрика - accuracy. <br/>
  Модель довольно быстро начала переобучаться и недостаточно хорошо обрабатывала валидационный сет.
  IMAGE
  
  
  * Затем я воспользовался обученной моделью MobileNet V2 для извлечения атрибутов изображения <br/>
  Я выбрал MobileNet V2 архитектуру из-за её эффективности. Я взял самую неглубокую версию с самым малым размером 
  изображения (96х96). Низкая глубина модели обусловлена невысокой сложностью задачи: небольшое количество классов и то, что объект 
  размещен почти на всей картинке. А малый размер изображений выбран потому, что средний размер исходных данных также невелик (множество изображений даже меньше 96х96). 
  
  К модели были добавлены два слоя - дропаут, для случайного выключения нейоронов, что способствует генерализации модели. 
  И последний с одним нейроном и sigmoid активацией.
  
  Чтобы не навредить весам загруженной модели, сначла я тренировал только последний слой.
  Затем значительно снизив начальную скорость обучения, разморозил веса всей модели. Я воспользовался <br/> 1cycle расписанием обучения, 
  чтобы сперва "разогреть" модель и не допустить разрушения модели из-за высоких градиентов.
  
  Модель достигла 100% на тренировочном сете, но на валидационном показывала лишь 0.97.
  Чтобы побороть подобный оверфит, стандартным решением будет увеличить количество данных. Этого можно достичь путем 
  аугментации изображений. Перед тем как приступить к этому, я провел небольшой анализ ошибок
  
  IMG
  * В ходе анализа ошибок я не обнаружил склонности модели к ошибкам в одном или другом классе. Также модель делала подавляющее большинство прогнозов
  с высокой уверенностью. Посмотрев на выборку неверно классифицированных изображий, я сам затруднился определить пол трети из них.
  
  * Далее я добавил аугментацию тренировочного сета.
</details>  
  
## Описание итоговой модели
<details>
  <summary>Раскрыть</summary><br/>  
  
  В работе
</details>

## Инструкция по применению сети
<details>
  <summary>Раскрыть</summary><br/> 
  
  1) Убедитесь, что у вас установлен python с tensorflow версии 2 и выше
  2) Скопируйте файл process.py вместе с папкой model в одну директорию. Можете разместить изображения в эту же папку.

  ![](desc_images/folder_files.png)

  3) Запустите командную строку и перейдите в директорию с файлами. 

  ![](desc_images/changefolder.jpg)

  4) Запустите скрипт указав путь к папке с изображениями.

  ![](desc_images/process_exec.png)

  5) После выполения, в папке где находится скрипт, появится новый файл process_results.json. В нем будут размещены результаты
  в виде { ‘img_1.jpg’: ‘male’, ‘img_2.jpg’: ‘female’, ...}
  </details>
  
## Инструкция по обучению сети
<details>
  <summary>Раскрыть</summary><br/>  
  
  В работе
</details>
